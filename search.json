[
  {
    "objectID": "venv_clean/lib/python3.12/site-packages/missingno-0.5.2.dist-info/LICENSE.html",
    "href": "venv_clean/lib/python3.12/site-packages/missingno-0.5.2.dist-info/LICENSE.html",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "Copyright (c) 2016 Aleksey Bilogur\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "skill_gap_analysis.html",
    "href": "skill_gap_analysis.html",
    "title": "Team Members’ Skill Proficiency Levels",
    "section": "",
    "text": "A numerical scale (1-5) to indicate proficiency levels:\n- 1 = Beginner\n- 2 = Basic Knowledge\n- 3 = Intermediate\n- 4 = Advanced\n- 5 = Expert\nPython\nSQL\nMachine Learning\nCloud Computing\nR\nAWS\n\n\nName\n\n\n\n\n\n\n\n\n\n\nTracy\n2\n3\n2\n2\n4\n2\n\n\nRyan\n4\n3\n2\n2\n4\n1"
  },
  {
    "objectID": "skill_gap_analysis.html#comparing-team-skills-to-industry-requirements",
    "href": "skill_gap_analysis.html#comparing-team-skills-to-industry-requirements",
    "title": "Team Members’ Skill Proficiency Levels",
    "section": "Comparing Team Skills to Industry Requirements",
    "text": "Comparing Team Skills to Industry Requirements\nWorking in the IT department requires a diverse set of skills that Ryan and Tracy will need to to develop to meet industry standards. The top skills in this line of work include experience with python, SQL, Machine Learning, Cloud Computing, R, Docker, and AWS. While Ryan has solid experience with Python, SQL, and R, Tracy has only limited experience with Python. Both need to improve their proficiency in Machine Learning, Cloud Computing, and AWS while familiarizing themselves with Docker, where they currently have no experience."
  },
  {
    "objectID": "skill_gap_analysis.html#improvement-plan",
    "href": "skill_gap_analysis.html#improvement-plan",
    "title": "Team Members’ Skill Proficiency Levels",
    "section": "Improvement Plan",
    "text": "Improvement Plan\nAlthough there is room for improvement in Python, SQL, and R skills, Ryan should prioritize enhancing his efficiency in Machine Learning, Cloud Computing, AWS, and Docker to achieve a well-rounded skill set. The same can be said for Tracy, who can also work on improving her efficiency with Python. Both individuals have similar skill gaps, but Ryan’s experience with Python can be leveraged to help Tracy with future challenges. Ryan can review Tracy’s Python code, providing feedback to help her write cleaner and more efficient code. Given both Ryan’s and Tracy’s other skill sets, using recommended resources will be essential in further developing their abilities.\nA valuable platform to improve and familiarize oneself with these topics is DataCamp, an online learning platform that helps aspiring data analysts and engineers learn data analytics through engaging activities. The platform offers several resources for learning data analysis, such as webinars, code-alongs, tutorials, blogs, and podcasts. DataCamp is also designed to accommodate individuals at different levels, offering courses for beginners, intermediate, and advanced learners. The website provides courses in Python, R, Cloud Computing, AWS, and Docker—topics that Ryan and Tracy are seeking to improve in.\nAnother resource to consider is Fullstack Academy, an online bootcamp for data analytics. The bootcamp helps individuals gain the skills needed to advance their career paths in coding, data analytics, AI, and Machine Learning, with the promise that students will develop their skills in 26 weeks. The data analytics bootcamp at Fullstack offers students a live online classroom environment that includes live instruction, exercises, and team projects. The curriculum covers data analytics with Excel, SQL, and Python, while also addressing the latest essentials of generative AI. This platform would provide Ryan and Tracy with essential building blocks to further their coding skills."
  },
  {
    "objectID": "ml_methods_2.html",
    "href": "ml_methods_2.html",
    "title": "ML Methods",
    "section": "",
    "text": "Unsupervised Clustering\nAs a group, we will be implementing an unsupervised clustering model using the K-mean algorithm. We are seeking to differentiate AI-related jobs postings from non-AI ones. AI-related job postings will be defined by AI-related keywords. The results will serve to tell us how how certain features separate AI-related job postings from non-AI.\n\n#from pyspark.sql import SparkSession\n## Load the Lightcast Job Posting Data\n#spark = SparkSession.builder \\\n#.appName(\"AI_vs_NonAI_JobPostings\") \\\n#.config(\"spark.driver.memory\", \"4g\") \\\n#.getOrCreate()\n\n\n#df = spark.read.option(\"header\", \"true\") \\\n#    .option(\"inferSchema\", \"true\") \\\n#    .option(\"multiLine\", \"true\") \\\n#    .option(\"escape\", \"\\\"\") \\\n#    .csv(\"./data/lightcast_job_postings.csv\")\n\n\n# Drop unnecessary columns\n#columns_to_drop = [\n#    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n#    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n#    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n#]\n#df = df.drop(*columns_to_drop)\n\n# Filter rows with non-null salary and classification columns\n#df = df.filter(\n#    (col(\"SALARY_FROM\").isNotNull()) &\n#    (col(\"SALARY_TO\").isNotNull()) &\n#    (col(\"TITLE_RAW\").isNotNull()) &\n#    (col(\"NAICS_2022_6\").isNotNull()) &\n#    (col(\"MIN_YEARS_EXPERIENCE\").isNotNull()) &\n#    (col(\"MAX_YEARS_EXPERIENCE\").isNotNull())\n#)\n\n# Convert salary columns to numeric\n#df = df.withColumn(\"SALARY_FROM\", col(\"SALARY_FROM\").cast(DoubleType()))\n#df = df.withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(DoubleType()))\n\n# Create average salary column\n#df = df.withColumn(\"AVG_SALARY\", (col(\"SALARY_FROM\") + col(\"SALARY_TO\")) / 2)\n\n# Convert experience columns and create average experience column\n#df = df.withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(DoubleType()))\n#df = df.withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(DoubleType()))\n#df = df.withColumn(\"AVG_YEARS_EXPERIENCE\", (col(\"MIN_YEARS_EXPERIENCE\") + col(\"MAX_YEARS_EXPERIENCE\")) / 2)\n\n# Remove rows with null values in critical columns\n#df = df.dropna(subset=['AVG_SALARY', 'TITLE_RAW', 'NAICS_2022_6', 'AVG_YEARS_EXPERIENCE'])\n\n# Lowercase the TITLE_RAW column for keyword matching\n#df = df.withColumn(\"TITLE_LOWER\", lower(col(\"TITLE_RAW\")))\n\n# List of AI keywords\n#ai_keywords = [\n#    \"ai\", \"artificial intelligence\", \"machine learning\", \"deep learning\",\n#    \"neural network\", \"nlp\", \"computer vision\", \"chatgpt\", \"gpt-3\", \"gpt-4\",\n#    \"llm\", \"large language model\"\n#]\n\n# Build condition for presence of AI keywords\n#ai_condition = None\n#for keyword in ai_keywords:\n#    condition = col(\"TITLE_LOWER\").contains(keyword)\n#    if ai_condition is None:\n#        ai_condition = condition\n#    else:\n#        ai_condition = ai_condition | condition\n\n# Create binary column IS_AI_ROLE\n#df = df.withColumn(\"IS_AI_ROLE\", when(ai_condition, 1).otherwise(0))\n\n\n# Define pipeline stages\n#title_indexer = StringIndexer(inputCol=\"TITLE_RAW\", outputCol=\"TITLE_ENCODED\", handleInvalid=\"keep\")\n#naics_indexer = StringIndexer(inputCol=\"NAICS_2022_6\", outputCol=\"NAICS_ENCODED\", handleInvalid=\"keep\")\n#assembler = VectorAssembler(\n#    inputCols=[\"TITLE_ENCODED\", \"NAICS_ENCODED\", \"AVG_SALARY\", \"AVG_YEARS_EXPERIENCE\"], \n#    outputCol=\"features\"\n#)\n#kmeans = KMeans(featuresCol=\"features\", predictionCol=\"CLUSTER\", k=2, seed=42)\n\n# Create pipeline\n#pipeline = Pipeline(stages=[title_indexer, naics_indexer, assembler, kmeans])\n\n# Fit pipeline\n#model = pipeline.fit(df)\n\n\n\nFeatures and Silhouette Score\nWe will be using the following features for our clustering model:\n\nAverage Salary, expected to capture pay differences\nJob Title (Encoded), expected to capture role differences\nNAICS Code (Encoded), expected to separate jobs by sectors\nAverage Years of Experience, expected to capture experience level differences\n\nGrouping these features in a cluster of 2, we found a silhouette score of approximately 0.695, indicating a good clustering structure. However, since the score is not closer to 1 than expected, reflecting the complexity between AI and non-AI job postings.\n\n\n\nIS_AI_ROLE\nCLUSTER\ncount\n\n\n\n\n1\n0\n47\n\n\n1\n1\n19\n\n\n0\n0\n2195\n\n\n0\n1\n1669\n\n\n\n\n# Transform data to get cluster predictions\n#predictions = model.transform(df)\n\n# Evaluate clustering\n#evaluator = ClusteringEvaluator(featuresCol=\"features\", predictionCol=\"CLUSTER\", metricName=\"silhouette\")\n#silhouette = evaluator.evaluate(predictions)\n#print(f\"Silhouette score = {silhouette}\")\n\n# Show cluster counts grouped by AI role\n#predictions.groupBy(\"IS_AI_ROLE\", \"CLUSTER\").count().show()\n\n\n\nPairwise Plots\nBelow are a series of pairwise plots showing the relationships between the features used in the clustering model, consisting of Average Salary, Job Title (Encoded), NAICS Code (Encoded), and Average Years of Experience. The plots seek to visualize how these features interact and potentially separate AI-related job postings from non-AI ones. From the plots, a clear relationship is not visible between the features due to the lower number of AI-related job postings in the dataset.\nIt would be unusual to see any AI jobs since AI jobs are not common in the hiring process. The few present in the visualizations are likely the ones that require higher technical skills in the ML domain. To further study our prompt, other processes will need to be performed.\n\n#import hvplot.pandas\n#import panel as pn\n#pn.extension()\n\n# Sample 5% of the data to reduce size for plotting\n#sample_pdf = predictions.select(\n#    \"AVG_SALARY\", \"TITLE_ENCODED\", \"NAICS_ENCODED\", \"AVG_YEARS_EXPERIENCE\", \"IS_AI_ROLE\"\n#).sample(fraction=0.05, seed=42).toPandas()\n\n# Map IS_AI_ROLE to string labels for coloring\n#sample_pdf['Role'] = sample_pdf['IS_AI_ROLE'].map({0: 'Non-AI', 1: 'AI'})\n\n# Columns to plot\n#cols = [\"AVG_SALARY\", \"TITLE_ENCODED\", \"NAICS_ENCODED\", \"AVG_YEARS_EXPERIENCE\"]\n\n#plots = []\n#for x in cols:\n#    for y in cols:\n#        if x != y:\n#            plot = sample_pdf.hvplot.scatter(\n#                x=x, y=y, by='Role', width=450, height=250, alpha=0.6, title=f\"{y} vs {x}\"\n#            )\n#            plots.append(plot)\n\n# Arrange plots in a grid with 2 columns\n#grid = pn.GridBox(*plots, ncols=2)\n\n# Save the interactive grid as an HTML file\n#grid.save(\"figures/interactive_plots.html\", embed=True)\n\nView Interactive Plots\n\n\nPCA 2D Visualization Excluding Salary\nGenerating a 2D PCA plot excluding salary to visualize the clustering of AI-related and non-AI jobs based served as a useful alternative to the previous pairwise plots. The following PCA plots consist of PC1 vs PC2, PC1 vs PC3, and PC2 vs PC3.\nThe PC1 vs PC2 plots shows some separation between clusters along PC1, but a lot of overlap along PC2. The PC1 vs PC3 plot demonstrates a clearer separation between the clusters, with cluster groups more distinctly divided along PC3. The PC2 vs PC3 presents moderate cluster separation, with the appearance of vertical banding along PC2.\nThe results of the PCA plots indicate the there are now two visually distinct clusters, which is an improvement from the previous pairwise plots. However, there is still confusion regarding which features strongly divide AI-related job postings from non-AI ones.\n\n#from pyspark.ml.feature import VectorAssembler, PCA\n#import seaborn as sns\n#import matplotlib.pyplot as plt\n\n# Step 1: Assemble features excluding AVG_SALARY\n#assembler_no_salary = VectorAssembler(\n#    inputCols=[\"TITLE_ENCODED\", \"NAICS_ENCODED\", \"AVG_YEARS_EXPERIENCE\"],\n#    outputCol=\"features_no_salary\"\n#)\n\n#df_features = assembler_no_salary.transform(predictions)\n\n# Step 2: Fit PCA with k=3 (max components for 3 features)\n#pca = PCA(k=3, inputCol=\"features_no_salary\", outputCol=\"pcaFeatures\")\n#pca_model = pca.fit(df_features)\n#pca_result = pca_model.transform(df_features)\n\n# Step 3: Convert to Pandas for plotting\n#pdf_pca = pca_result.select(\"pcaFeatures\", \"CLUSTER\").toPandas()\n\n# Extract PCA components to separate columns\n#pdf_pca[\"PC1\"] = pdf_pca[\"pcaFeatures\"].apply(lambda x: x[0])\n#pdf_pca[\"PC2\"] = pdf_pca[\"pcaFeatures\"].apply(lambda x: x[1])\n#pdf_pca[\"PC3\"] = pdf_pca[\"pcaFeatures\"].apply(lambda x: x[2])\n\n# Step 4: Plotting and saving function\n#def plot_pcs_save(x, y, filename):\n#    sns.scatterplot(data=pdf_pca, x=x, y=y, hue=\"CLUSTER\", palette=\"deep\", alpha=0.6)\n#    plt.title(f\"PCA Scatter Plot: {x} vs {y}\")\n#    plt.savefig(f\"figures/{filename}\")\n#    plt.close()\n\n# Save PCA scatter plots as PNG images\n#plot_pcs_save(\"PC1\", \"PC2\", \"pca_PC1_vs_PC2.png\")\n#plot_pcs_save(\"PC1\", \"PC3\", \"pca_PC1_vs_PC3.png\")\n#plot_pcs_save(\"PC2\", \"PC3\", \"pca_PC2_vs_PC3.png\")\n\n\n\n\n\n# pca loadings from the data, and it will show which variable contributes to which component\n#from pyspark.ml.feature import VectorAssembler, PCA\n#import pandas as pd\n\n# Replace with your actual feature columns\n#features_list = [\"TITLE_ENCODED\", \"NAICS_ENCODED\", \"AVG_YEARS_EXPERIENCE\"]\n\n# Step 1: Assemble features into a vector column\n#assembler = VectorAssembler(inputCols=features_list, outputCol=\"features_no_salary\")\n#df_features = assembler.transform(predictions)\n\n# Step 2: Fit PCA with k=3 components\n#no_of_components = 3\n#pca = PCA(k=no_of_components, inputCol=\"features_no_salary\", outputCol=\"pcaFeatures\")\n#pca_model = pca.fit(df_features)\n\n\n# Step 3: Transform data to get PCA features (optional, for inspection)\n#pca_result = pca_model.transform(df_features).select(\"pcaFeatures\")\n#pca_result.show(truncate=False)\n\n\n\nPCA Loadings Table\n\n\n\nVariable\nPCA1\nPCA2\nPCA3\n\n\n\n\nTITLE_ENCODED\n-0.999826\n0.018638\n-0.000502\n\n\nNAICS_ENCODED\n-0.018640\n-0.999809\n0.005905\n\n\nAVG_YEARS_EXPERIENCE\n-0.000392\n0.005913\n0.999982\n\n\n\nLoading the data set, PC1 is entirely dominated by TITLE_ENCODED, with a coefficient of 0.999. This means the differences in job titles are the main factor separating the clusters. The second largest variance, PC2, is dominated by NAICS_ENCODED with a coefficient of 0.998, indicating that the industry sector is the next most important factor. PC3 is dominated by AVG_YEARS_EXPERIENCE with a coefficient of 0.999, suggesting that experience level is also a significant factor in distinguishing between job postings, which could lead to differences in salary.\n\n\nDifferences Between AI and Non-AI Job Postings Using K-Means Clustering\nUsing K-means clustering, we identified two clusters in our dataset through a series of processes including selecting features, calculating a silhouette score, and visualizing the data using PCA 2D plots. Although this is an unsupervised learning method, the clusters likely correspond to AI-related and non-AI jobs postings based on the features used. Clusters are primarily separated by job titles, a strong indicator of whether a job is AI-related. Industry classification and experience level also play a role in distinguishing between the two types of job postings. The process, while not definitive, provides insights into the characteristics that differentiate AI-related jobs postings from non-AI ones in the dataset.\n\n# Step 4: Extract PCA loadings matrix\n#loadings_matrix = pca_model.pc.toArray()\n\n# Step 5: Create Pandas DataFrame for loadings\n#loading_scores = pd.DataFrame(loadings_matrix, columns=[f\"PCA{i+1}\" for i in range(no_of_components)])\n#loading_scores[\"Variable\"] = features_list\n\n# Reorder columns for readability\n#loading_scores = loading_scores[[\"Variable\"] + [f\"PCA{i+1}\" for i in range(no_of_components)]]\n\n# Step 6: Print loadings\n#print(loading_scores)\n\n\n\nLogistic Regression\n\n#from pyspark.sql import SparkSession\n#from pyspark.sql.functions import col, when, lower\n#from pyspark.sql.types import DoubleType\n#from pyspark.ml import Pipeline\n#from pyspark.ml.feature import StringIndexer, VectorAssembler\n#from pyspark.ml.classification import LogisticRegression\n#from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# drop unnecessary columns\n#columns_to_drop = [\"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\", \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\", \"SOC_2\", \"SOC_3\", \"SOC_5\"]\n#df = df.drop(*columns_to_drop)\n\n# filter for non-null critical columns\n#df = df.filter((col(\"TITLE_RAW\").isNotNull()) & (col(\"NAICS_2022_6\").isNotNull()) & (col(\"MIN_YEARS_EXPERIENCE\").isNotNull()) & (col(\"MAX_YEARS_EXPERIENCE\").isNotNull()))\n\n# convert experience columns and create average\n#df = df.withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(DoubleType()))\n#df = df.withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(DoubleType()))\n#df = df.withColumn(\"AVG_YEARS_EXPERIENCE\", (col(\"MIN_YEARS_EXPERIENCE\") + col(\"MAX_YEARS_EXPERIENCE\")) / 2)\n\n# create ai role indicator\n#ai_keywords = [\"ai\", \"artificial intelligence\", \"machine learning\", \"deep learning\", \"neural network\", \"nlp\", \"computer vision\", \"chatgpt\", \"gpt-3\", \"gpt-4\", \"llm\", \"large language model\"]\n#df = df.withColumn(\"TITLE_LOWER\", lower(col(\"TITLE_RAW\")))\n#ai_condition = None\n#for keyword in ai_keywords:\n#    condition = col(\"TITLE_LOWER\").contains(keyword)\n#    ai_condition = condition if ai_condition is None else ai_condition | condition\n#df = df.withColumn(\"IS_AI_ROLE\", when(ai_condition, 1).otherwise(0))\n\n# add class weights for imbalance\n#num_total = df.count()\n#num_ai = df.filter(col(\"IS_AI_ROLE\") == 1).count()\n#num_non_ai = num_total - num_ai\n#weight_ai = num_total / (2 * num_ai)\n#weight_non_ai = num_total / (2 * num_non_ai)\n#df = df.withColumn(\"classWeightCol\", when(col(\"IS_AI_ROLE\") == 1, weight_ai).otherwise(weight_non_ai))\n\n# encode categorical column\n#naics_indexer = StringIndexer(inputCol=\"NAICS_2022_6\", outputCol=\"NAICS_ENCODED\", handleInvalid=\"keep\")\n\n# assemble features\n#assembler = VectorAssembler(inputCols=[\"NAICS_ENCODED\", \"AVG_YEARS_EXPERIENCE\"], outputCol=\"features\")\n\n# logistic regression with class weights\n#lr = LogisticRegression(featuresCol=\"features\", labelCol=\"IS_AI_ROLE\", weightCol=\"classWeightCol\", maxIter=20)\n\n# build pipeline\n#pipeline = Pipeline(stages=[naics_indexer, assembler, lr])\n\n# split data into train and test\n#train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n\n# fit model\n#model = pipeline.fit(train_df)\n\n# make predictions\n#predictions = model.transform(test_df)\n#predictions.select(\"IS_AI_ROLE\", \"prediction\", \"probability\").show(5)\n\n# evaluate roc auc\n#roc_evaluator = BinaryClassificationEvaluator(labelCol=\"IS_AI_ROLE\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n#roc_auc = roc_evaluator.evaluate(predictions)\n#print(f\"roc auc: {roc_auc}\")\n\n# evaluate accuracy\n#accuracy = predictions.filter(predictions.IS_AI_ROLE == predictions.prediction).count() / predictions.count()\n#print(f\"accuracy: {accuracy}\")\n\n# evaluate precision, recall, f1\n#tp = predictions.filter((col(\"IS_AI_ROLE\") == 1) & (col(\"prediction\") == 1)).count()\n#fp = predictions.filter((col(\"IS_AI_ROLE\") == 0) & (col(\"prediction\") == 1)).count()\n#fn = predictions.filter((col(\"IS_AI_ROLE\") == 1) & (col(\"prediction\") == 0)).count()\n#precision = tp / (tp + fp) if tp + fp &gt; 0 else 0\n#recall = tp / (tp + fn) if tp + fn &gt; 0 else 0\n#f1 = 2 * (precision * recall) / (precision + recall) if precision + recall &gt; 0 else 0\n#print(f\"precision: {precision}, recall: {recall}, f1 score: {f1}\")\n\nThe logistic regression model for predicting AI-related jobs was trained on a dataset with a highly imbalanced target variable, where AI jobs are much less frequent than non-AI jobs. The features used in this iteration were NAICS_2022_6 (encoded as categorical) and AVG_YEARS_EXPERIENCE (numeric), while other potentially predictive features such as salary or job title information were not included. After implementing class weighting to address the imbalance, the model achieved a ROC AUC of 0.62, indicating modest discriminative ability between AI and non-AI jobs. Overall accuracy was 0.64, which is lower than the unweighted model but reflects that the model now predicts some AI jobs instead of defaulting to non-AI. Precision was very low at 0.029, meaning that most predicted AI jobs are actually non-AI, while recall was 0.515, showing that the model correctly identifies about half of the actual AI jobs. The F1 score was 0.055, reflecting the low precision despite the improved recall.\nThe model’s main strength lies in its ability to recognize minority class instances, which was previously ignored in the unweighted version where precision, recall, and F1 were zero. However, the model has several limitations. Precision remains low, the features used are limited, and the overall ROC AUC suggests only moderate separation between classes. Potential improvements include incorporating additional features such as AVG_SALARY, MIN_YEARS_EXPERIENCE, and engineered job title features to capture more predictive information. Alternative classifiers like Random Forest, Gradient Boosted Trees, or XGBoost may better handle imbalance and capture non-linear patterns. Threshold tuning and sampling techniques such as oversampling AI jobs or undersampling non-AI jobs could further improve performance. Overall, the class-weighted logistic regression demonstrates progress in identifying AI jobs, particularly in improving recall, but additional features and modeling strategies are needed to increase precision and achieve a more balanced and reliable classification."
  },
  {
    "objectID": "ai_vs_traditional.html",
    "href": "ai_vs_traditional.html",
    "title": "AI vs Traditional Jobs Research",
    "section": "",
    "text": "Prakash Adhikari, faculty member of the Faculty of Humanities and Social Sciences, Department of Conflict, Peace, and Development Studies at Tribhuvan University in Kirtipur, Nepal, explains how artificial intelligence (AI) is changing jobs in two significant ways. It is creating new types of jobs while at the same time causing problems for existing ones. AI, which is deeply based on technologies such as machine learning and robotics, is suitable for automating tasks and helping people do more valuable work. Simply put, AI can make work more productive but also brings risks such as job loss, skill gaps, and inequality.\nFurther studies reveal that jobs involving repetitive tasks, such as those in factories, office work, and some customer service roles, are most likely to become automated in the future. At the same time, new jobs are emerging in areas like data analysis, software development, and healthcare using AI. Higher-skilled jobs often benefit from AI by becoming more efficient and better paid, while many low- and middle-skill jobs are at serious risk of disappearing.\nAdhikari suggests plans to help people adapt to these changes. These plans include providing training and lifelong learning opportunities, improving social safety nets like unemployment benefits, creating fair and clear AI rules in employment sectors, and pushing for innovation in smaller businesses outside of major tech centers. While AI-driven innovations offer many benefits, Adhikari urges caution, calling for more detailed research to understand how AI affects workers and what policies work best in different industries to reduce job loss while promoting new innovations."
  },
  {
    "objectID": "ai_vs_traditional.html#exploring-the-nexus-between-artificial-intelligence-and-job-displacement-a-literature-review",
    "href": "ai_vs_traditional.html#exploring-the-nexus-between-artificial-intelligence-and-job-displacement-a-literature-review",
    "title": "AI vs Traditional Jobs Research",
    "section": "",
    "text": "Prakash Adhikari, faculty member of the Faculty of Humanities and Social Sciences, Department of Conflict, Peace, and Development Studies at Tribhuvan University in Kirtipur, Nepal, explains how artificial intelligence (AI) is changing jobs in two significant ways. It is creating new types of jobs while at the same time causing problems for existing ones. AI, which is deeply based on technologies such as machine learning and robotics, is suitable for automating tasks and helping people do more valuable work. Simply put, AI can make work more productive but also brings risks such as job loss, skill gaps, and inequality.\nFurther studies reveal that jobs involving repetitive tasks, such as those in factories, office work, and some customer service roles, are most likely to become automated in the future. At the same time, new jobs are emerging in areas like data analysis, software development, and healthcare using AI. Higher-skilled jobs often benefit from AI by becoming more efficient and better paid, while many low- and middle-skill jobs are at serious risk of disappearing.\nAdhikari suggests plans to help people adapt to these changes. These plans include providing training and lifelong learning opportunities, improving social safety nets like unemployment benefits, creating fair and clear AI rules in employment sectors, and pushing for innovation in smaller businesses outside of major tech centers. While AI-driven innovations offer many benefits, Adhikari urges caution, calling for more detailed research to understand how AI affects workers and what policies work best in different industries to reduce job loss while promoting new innovations."
  },
  {
    "objectID": "ai_vs_traditional.html#modeling-the-complex-interplay-dynamics-of-job-displacement-and-evolution-of-artificial-intelligence-in-a-socio-economic-landscape",
    "href": "ai_vs_traditional.html#modeling-the-complex-interplay-dynamics-of-job-displacement-and-evolution-of-artificial-intelligence-in-a-socio-economic-landscape",
    "title": "AI vs Traditional Jobs Research",
    "section": "Modeling the Complex Interplay: Dynamics of Job Displacement and Evolution of Artificial Intelligence in a Socio-Economic Landscape",
    "text": "Modeling the Complex Interplay: Dynamics of Job Displacement and Evolution of Artificial Intelligence in a Socio-Economic Landscape\nThe research document, written and organized by three professors in the Department of Mathematics at Mizan-Tepi University, Tepi, Ethiopia, examines the impact of rapid advances in artificial intelligence (AI) on job security and the economy, considering the relationship between AI and employment as an interconnected, evolving, and complex phenomenon. They focus on how the adoption of AI is changing the labor markets over time and under what conditions jobs are lost, transformed, or balanced with the introduction of automation. The argument is that a viewpoint centered on technology is inadequate, and that a thorough approach, incorporating feedback loops and nonlinear effects, is necessary to understand the long-term implications better. Their goal is to build a foundation that mitigates the adverse impact of AI while promoting its enhanced productivity.\nThe study employs the Lotka-Volterra model, also known as the predator-prey model, to illustrate the interaction between human jobs and AI capabilities. Analyzing the model reveals different outcomes, including job growth, job loss, the coevolution of jobs and AI, or the decline of both. The results of the model show that a situation with no jobs or AI is unstable; stable coexistence is possible if AI growth is controlled and human job creation experiences healthy growth. The outcome primarily depends on the speed of AI adoption, its productivity effects, and job creation.\nThe solution involves slowing down AI adoption to prevent shocks, investing in worker up-skilling, and fostering the development of job-creating industries. The article also suggests expanding the model to include wages, education, regulations, and capital flows, while, more importantly, using real data to view and manage accurate predictions. They suggest that suitable policies will enable the smooth integration of AI into the workplace, thereby reducing the negative impact on jobs and the livelihoods of employees."
  },
  {
    "objectID": "ai_vs_traditional.html#the-potential-impact-of-ai-innovations-on-u.s.-occupations",
    "href": "ai_vs_traditional.html#the-potential-impact-of-ai-innovations-on-u.s.-occupations",
    "title": "AI vs Traditional Jobs Research",
    "section": "The Potential Impact of AI Innovations on U.S. Occupations",
    "text": "The Potential Impact of AI Innovations on U.S. Occupations\nAmid the rapid rise of artificial intelligence (AI) across industries, this study presents a novel, data-driven approach to understanding how AI innovations influence U.S. occupations broadly and at the level of individual tasks. The authors develop an “AI Impact (AII)” measure using deep learning natural language processing to match 17,879 occupational task descriptions from O*NET with 24,758 AI-related patents filed between 2015 and 2022. By analyzing patent text and using advanced semantic models (Sentence-T5), the AII quantifies how closely each task aligns with emerging AI technologies. Unlike earlier, coarse-grained methods relying on manual labeling or broad skill categories, this approach captures subtler, task-specific dynamics of AI impact, offering a more accurate and scalable picture of automation potential across industries.\nThe study reveals that AI increasingly influences both routine and nonroutine tasks, challenging the belief that automation mainly threatens repetitive work. Occupations with high AI exposure like as software developers, cardiovascular technologists, and air traffic controllers are concentrated in structured, data-driven sectors like healthcare, IT, and manufacturing, where AI enhances diagnostics, predictive maintenance, and workflow optimization. Meanwhile, jobs in agriculture, construction, and hospitality remain less affected due to their reliance on manual and context-dependent skills. Overall, the study finds that AI’s labor impact is moderated by its role in augmenting rather than replacing human expertise and by ongoing workforce shortages in high-demand fields. Instead of widespread displacement, AI is reshaping work by redistributing effort, supporting complex decision-making, and amplifying productivity across industries."
  },
  {
    "objectID": "ai_vs_traditional.html#employees-perceptions-of-the-implementation-of-robotics-artificial-intelligence-and-automation-raia-on-job-satisfaction-job-security-and-employability",
    "href": "ai_vs_traditional.html#employees-perceptions-of-the-implementation-of-robotics-artificial-intelligence-and-automation-raia-on-job-satisfaction-job-security-and-employability",
    "title": "AI vs Traditional Jobs Research",
    "section": "Employees’ Perceptions of the Implementation of Robotics, Artificial Intelligence, and Automation (RAIA) on Job Satisfaction, Job Security, and Employability",
    "text": "Employees’ Perceptions of the Implementation of Robotics, Artificial Intelligence, and Automation (RAIA) on Job Satisfaction, Job Security, and Employability\nAs robotics and artificial intelligence reshape workplaces, this study examines how employees perceive these changes. Drawing on 21 interviews across consulting, accounting, and hospitality, it highlights both the efficiency gains of RAIA and the ongoing importance of human traits like empathy and creativity. The study found that while automation and AI enhance productivity and efficiency by removing repetitive tasks, human qualities like empathy, creativity, and judgment remain irreplaceable. Employees acknowledged both opportunities and threats in this transition and recognized RAIA’s potential to improve job quality and satisfaction while also fueling fears about job loss, data privacy, and skill obsolescence.\nThis tension produces what the authors describe as a “job satisfaction dilemma,” where enthusiasm for innovation coexists with anxiety over job stability, privacy concerns, and the need for continuous skill development.Perceptions vary by role: knowledge-based employees see automation as a productivity partner, while those in routine positions feel more vulnerable. The research shows that successful RAIA adoption requires more than technology, as it also calls for transparent communication, ethical governance, and active workforce support.\nBy positioning RAIA as a tool to complement rather than compete with human labor, organizations can foster trust, adaptability, and long-term employability. Ultimately, the study underscores that in an age of intelligent machines, human adaptability, emotional insight, and lifelong learning remain the foundation of meaningful work."
  },
  {
    "objectID": "ai_vs_traditional.html#redefining-careers-in-the-age-of-artificial-intelligence",
    "href": "ai_vs_traditional.html#redefining-careers-in-the-age-of-artificial-intelligence",
    "title": "AI vs Traditional Jobs Research",
    "section": "Redefining careers in the age of artificial intelligence",
    "text": "Redefining careers in the age of artificial intelligence\nArtificial intelligence (AI) is transforming the job market by both displacing certain roles and creating new opportunities. Routine and manual tasks, such as telemarketing, retail work, and data entry, are increasingly automated, while jobs requiring empathy, creativity, and complex problem-solving, like teaching, healthcare, and design, remain resilient. This shift highlights the evolving collaboration between humans and machines.\nNew roles are emerging to support AI systems, including positions that train AI, interpret AI decisions for humans, and ensure responsible and ethical AI practices. Industries across finance, healthcare, education, and technology are creating specialized positions that complement human skills rather than replace them entirely. These roles emphasize the importance of technical expertise, interdisciplinary knowledge, and ethical awareness.\nTo succeed in an AI-driven workforce, individuals and businesses must focus on skill development, adaptability, and lifelong learning. Key skills include data literacy, familiarity with AI, emotional intelligence, creativity, and problem-solving. Businesses can support this transition by integrating AI responsibly, fostering innovation, and providing opportunities for upskilling, ensuring that human capabilities continue to thrive alongside technological advancements."
  },
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "Data Analysis",
    "section": "",
    "text": "The Unnecessary Columns:\n\nID\nURL\nACTIVE_URLS\nDUPLICATES\nLAST_UPDATED_TIMESTAMP\nNAICS2\nNAICS3\nNAICS4\nNAICS5\nNAICS6\nSOC_2\nSOC_3\nSOC_5\n\nWith the removal of older NAICS and SOC codes, our dataset now retains only the most current classification columns: NAICS_2022_6 for industry and SOC_2021_4 for occupation. This streamlines our analysis by focusing on up-to-date standards, reducing redundancy, and ensuring consistency in categorizing job postings."
  },
  {
    "objectID": "data_analysis.html#dropping-unnecessary-columns",
    "href": "data_analysis.html#dropping-unnecessary-columns",
    "title": "Data Analysis",
    "section": "",
    "text": "The Unnecessary Columns:\n\nID\nURL\nACTIVE_URLS\nDUPLICATES\nLAST_UPDATED_TIMESTAMP\nNAICS2\nNAICS3\nNAICS4\nNAICS5\nNAICS6\nSOC_2\nSOC_3\nSOC_5\n\nWith the removal of older NAICS and SOC codes, our dataset now retains only the most current classification columns: NAICS_2022_6 for industry and SOC_2021_4 for occupation. This streamlines our analysis by focusing on up-to-date standards, reducing redundancy, and ensuring consistency in categorizing job postings."
  },
  {
    "objectID": "data_analysis.html#job-postings-by-industry",
    "href": "data_analysis.html#job-postings-by-industry",
    "title": "Data Analysis",
    "section": "2 Job Postings by Industry",
    "text": "2 Job Postings by Industry\n\n\nThe amount of jobs an industry publishes is indicative of their growth, need for new talent, and increase in goals. Such values help improve the attractiveness of an industry to students, career changers or other industries looking to collaborate.\nThe bar chart depicts the job postings by industry, with a majority of postings within a select few industries. An Unclassified Industry has the highest amount of postings, amassing over 9,000. This lead is followed by other industries such as Custom Computer Programming Services, Administrative Management and General Management Consulting Services, Employment Placement Agencies, and Computer Systems Design Services in descending value and number of job postings between 5,000 and 4,000.\nThe remaining industries amount to a much smaller number of postings, which indicates their low representation. This lower hiring demand could be a result of disinterest in field from college graduates and skilled professionals or the lack of proper outreach about such industries to the general public. Either way, it is evident that the industries that deal with computer-based technology have higher volumes of job postings to meet the demand of companies and other businesses within their sector."
  },
  {
    "objectID": "data_analysis.html#salary-distribution-by-industry",
    "href": "data_analysis.html#salary-distribution-by-industry",
    "title": "Data Analysis",
    "section": "3 Salary Distribution by Industry",
    "text": "3 Salary Distribution by Industry\n\nAs salary is a strong determining factors in people’s choice of career and deciding between industries, it is important to evaluate how 20 industries published by NAICS compensate their talent across the board. Some industries like Software Publishers, Administrative Management and General Management Consultant Services, and Web Search Portals and All Other Information Services display wide salary spreads, indicated by tall boxes in the plot. These industires also have large high-salary outliers, with salaries reaching almost $500k.\nThe median and interquartile ranges also differ between industries. For example, the Temporary Help Services and Direct Health and Medical Insurance Carriers industries have the tighter cluster of salaries, suggesting more consistent pay ranges in various subsectors and across titles and other levels of seniority. Unlike the other widespread industries, where salary expectations might differ drastically from company to company or region to region.\nOverall, this distribution highlights how industry choice can also affect earning potential in the long-run and cap salaries despite years of experience, skillset, or educational level."
  },
  {
    "objectID": "data_analysis.html#remote-vs.-on-site-jobs",
    "href": "data_analysis.html#remote-vs.-on-site-jobs",
    "title": "Data Analysis",
    "section": "4 Remote vs. On-Site Jobs",
    "text": "4 Remote vs. On-Site Jobs\n\nAfter 2020, there has been a large influx of the necessity for work-life balance and that priority was heavily influenced by remote work that maintained industries during the COVID-19 lockdown mandates. However, as society moves past the time of quarantine, it is becoming a prevalent question on if these multitude of remote jobs that offer flexibilty would be carried along into the future.\nThe piechart shows how the lack of proper documentaion can affect analysis as 78.3% of jobs are not classified as remote, hybrid remote, or not remote. Although, this took up the larger portion of the diagram, 17% of those jobs are Remote, with another 3.11% being Hybrid remote (some days in-office and others virtually), which account for a fifith of all job postings. This demonstrates that flexible work arrangements are an important factor to both the industry, in terms of their expecations for performance, as well as applicants and their need to for a healthy balance between work and personal life.\nAdditionally, less than 2% of jobs are not Remote or are completely on-site which further corroborates the idea that employers prefer and adveritse flexibilty over strict in-person requirements."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ryan Martin and Tracy Anyasi",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "venv_clean/lib/python3.12/site-packages/narwhals-2.4.0.dist-info/licenses/LICENSE.html",
    "href": "venv_clean/lib/python3.12/site-packages/narwhals-2.4.0.dist-info/licenses/LICENSE.html",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "MIT License\nCopyright (c) 2024, Marco Gorelli\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  }
]