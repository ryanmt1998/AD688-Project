[
  {
    "objectID": "ml_methods.html",
    "href": "ml_methods.html",
    "title": "ML Methods",
    "section": "",
    "text": "As a group, we will be implementing an unsupervised clustering model using the K-mean algorithm. We are seeking to differentiate AI-related jobs postings from non-AI ones. AI-related job postings will be defined by AI-related keywords. The results will serve to tell us how how certain features separate AI-related job postings from non-AI.\n\nfrom pyspark.sql.functions import col, when, lower\nfrom pyspark.sql.types import DoubleType\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.evaluation import ClusteringEvaluator\n\n\nfrom pyspark.sql import SparkSession\n## Load the Lightcast Job Posting Data\nspark = SparkSession.builder \\\n.appName(\"AI_vs_NonAI_JobPostings\") \\\n.config(\"spark.driver.memory\", \"4g\") \\\n.getOrCreate()\n\n\ndf = spark.read.option(\"header\", \"true\") \\\n    .option(\"inferSchema\", \"true\") \\\n    .option(\"multiLine\", \"true\") \\\n    .option(\"escape\", \"\\\"\") \\\n    .csv(\"./data/lightcast_job_postings.csv\")\n\n\n# Drop unnecessary columns\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\ndf = df.drop(*columns_to_drop)\n\n# Filter rows with non-null salary and classification columns\ndf = df.filter(\n    (col(\"SALARY_FROM\").isNotNull()) &\n    (col(\"SALARY_TO\").isNotNull()) &\n    (col(\"TITLE_RAW\").isNotNull()) &\n    (col(\"NAICS_2022_6\").isNotNull()) &\n    (col(\"MIN_YEARS_EXPERIENCE\").isNotNull()) &\n    (col(\"MAX_YEARS_EXPERIENCE\").isNotNull())\n)\n\n# Convert salary columns to numeric\ndf = df.withColumn(\"SALARY_FROM\", col(\"SALARY_FROM\").cast(DoubleType()))\ndf = df.withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(DoubleType()))\n\n# Create average salary column\ndf = df.withColumn(\"AVG_SALARY\", (col(\"SALARY_FROM\") + col(\"SALARY_TO\")) / 2)\n\n# Convert experience columns and create average experience column\ndf = df.withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(DoubleType()))\ndf = df.withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(DoubleType()))\ndf = df.withColumn(\"AVG_YEARS_EXPERIENCE\", (col(\"MIN_YEARS_EXPERIENCE\") + col(\"MAX_YEARS_EXPERIENCE\")) / 2)\n\n# Remove rows with null values in critical columns\ndf = df.dropna(subset=['AVG_SALARY', 'TITLE_RAW', 'NAICS_2022_6', 'AVG_YEARS_EXPERIENCE'])\n\n# Lowercase the TITLE_RAW column for keyword matching\ndf = df.withColumn(\"TITLE_LOWER\", lower(col(\"TITLE_RAW\")))\n\n# List of AI keywords\nai_keywords = [\n    \"ai\", \"artificial intelligence\", \"machine learning\", \"deep learning\",\n    \"neural network\", \"nlp\", \"computer vision\", \"chatgpt\", \"gpt-3\", \"gpt-4\",\n    \"llm\", \"large language model\"\n]\n\n# Build condition for presence of AI keywords\nai_condition = None\nfor keyword in ai_keywords:\n    condition = col(\"TITLE_LOWER\").contains(keyword)\n    if ai_condition is None:\n        ai_condition = condition\n    else:\n        ai_condition = ai_condition | condition\n\n# Create binary column IS_AI_ROLE\ndf = df.withColumn(\"IS_AI_ROLE\", when(ai_condition, 1).otherwise(0))\n\n\n# Define pipeline stages\ntitle_indexer = StringIndexer(inputCol=\"TITLE_RAW\", outputCol=\"TITLE_ENCODED\", handleInvalid=\"keep\")\nnaics_indexer = StringIndexer(inputCol=\"NAICS_2022_6\", outputCol=\"NAICS_ENCODED\", handleInvalid=\"keep\")\nassembler = VectorAssembler(\n    inputCols=[\"TITLE_ENCODED\", \"NAICS_ENCODED\", \"AVG_SALARY\", \"AVG_YEARS_EXPERIENCE\"], \n    outputCol=\"features\"\n)\nkmeans = KMeans(featuresCol=\"features\", predictionCol=\"CLUSTER\", k=2, seed=42)\n\n# Create pipeline\npipeline = Pipeline(stages=[title_indexer, naics_indexer, assembler, kmeans])\n\n# Fit pipeline\nmodel = pipeline.fit(df)"
  },
  {
    "objectID": "ml_methods.html#unsupervised-clustering",
    "href": "ml_methods.html#unsupervised-clustering",
    "title": "ML Methods",
    "section": "",
    "text": "As a group, we will be implementing an unsupervised clustering model using the K-mean algorithm. We are seeking to differentiate AI-related jobs postings from non-AI ones. AI-related job postings will be defined by AI-related keywords. The results will serve to tell us how how certain features separate AI-related job postings from non-AI.\n\nfrom pyspark.sql.functions import col, when, lower\nfrom pyspark.sql.types import DoubleType\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.evaluation import ClusteringEvaluator\n\n\nfrom pyspark.sql import SparkSession\n## Load the Lightcast Job Posting Data\nspark = SparkSession.builder \\\n.appName(\"AI_vs_NonAI_JobPostings\") \\\n.config(\"spark.driver.memory\", \"4g\") \\\n.getOrCreate()\n\n\ndf = spark.read.option(\"header\", \"true\") \\\n    .option(\"inferSchema\", \"true\") \\\n    .option(\"multiLine\", \"true\") \\\n    .option(\"escape\", \"\\\"\") \\\n    .csv(\"./data/lightcast_job_postings.csv\")\n\n\n# Drop unnecessary columns\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\ndf = df.drop(*columns_to_drop)\n\n# Filter rows with non-null salary and classification columns\ndf = df.filter(\n    (col(\"SALARY_FROM\").isNotNull()) &\n    (col(\"SALARY_TO\").isNotNull()) &\n    (col(\"TITLE_RAW\").isNotNull()) &\n    (col(\"NAICS_2022_6\").isNotNull()) &\n    (col(\"MIN_YEARS_EXPERIENCE\").isNotNull()) &\n    (col(\"MAX_YEARS_EXPERIENCE\").isNotNull())\n)\n\n# Convert salary columns to numeric\ndf = df.withColumn(\"SALARY_FROM\", col(\"SALARY_FROM\").cast(DoubleType()))\ndf = df.withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(DoubleType()))\n\n# Create average salary column\ndf = df.withColumn(\"AVG_SALARY\", (col(\"SALARY_FROM\") + col(\"SALARY_TO\")) / 2)\n\n# Convert experience columns and create average experience column\ndf = df.withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(DoubleType()))\ndf = df.withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(DoubleType()))\ndf = df.withColumn(\"AVG_YEARS_EXPERIENCE\", (col(\"MIN_YEARS_EXPERIENCE\") + col(\"MAX_YEARS_EXPERIENCE\")) / 2)\n\n# Remove rows with null values in critical columns\ndf = df.dropna(subset=['AVG_SALARY', 'TITLE_RAW', 'NAICS_2022_6', 'AVG_YEARS_EXPERIENCE'])\n\n# Lowercase the TITLE_RAW column for keyword matching\ndf = df.withColumn(\"TITLE_LOWER\", lower(col(\"TITLE_RAW\")))\n\n# List of AI keywords\nai_keywords = [\n    \"ai\", \"artificial intelligence\", \"machine learning\", \"deep learning\",\n    \"neural network\", \"nlp\", \"computer vision\", \"chatgpt\", \"gpt-3\", \"gpt-4\",\n    \"llm\", \"large language model\"\n]\n\n# Build condition for presence of AI keywords\nai_condition = None\nfor keyword in ai_keywords:\n    condition = col(\"TITLE_LOWER\").contains(keyword)\n    if ai_condition is None:\n        ai_condition = condition\n    else:\n        ai_condition = ai_condition | condition\n\n# Create binary column IS_AI_ROLE\ndf = df.withColumn(\"IS_AI_ROLE\", when(ai_condition, 1).otherwise(0))\n\n\n# Define pipeline stages\ntitle_indexer = StringIndexer(inputCol=\"TITLE_RAW\", outputCol=\"TITLE_ENCODED\", handleInvalid=\"keep\")\nnaics_indexer = StringIndexer(inputCol=\"NAICS_2022_6\", outputCol=\"NAICS_ENCODED\", handleInvalid=\"keep\")\nassembler = VectorAssembler(\n    inputCols=[\"TITLE_ENCODED\", \"NAICS_ENCODED\", \"AVG_SALARY\", \"AVG_YEARS_EXPERIENCE\"], \n    outputCol=\"features\"\n)\nkmeans = KMeans(featuresCol=\"features\", predictionCol=\"CLUSTER\", k=2, seed=42)\n\n# Create pipeline\npipeline = Pipeline(stages=[title_indexer, naics_indexer, assembler, kmeans])\n\n# Fit pipeline\nmodel = pipeline.fit(df)"
  }
]