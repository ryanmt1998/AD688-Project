{
  "cells": [
    {
      "cell_type": "raw",
      "id": "3570d3ad",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "title: \"ML Methods\"\n",
        "format: html\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed9d9137",
      "metadata": {},
      "source": [
        "# Unsupervised Clustering\n",
        "\n",
        "As a group, we will be implementing an unsupervised clustering model using the K-mean algorithm. We are seeking to differentiate AI-related jobs postings from non-AI ones. AI-related job postings will be defined by AI-related keywords. The results will serve to tell us how how certain features separate AI-related job postings from non-AI. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4f129153",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, when, lower\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "53735766",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "## Load the Lightcast Job Posting Data\n",
        "spark = SparkSession.builder \\\n",
        ".appName(\"AI_vs_NonAI_JobPostings\") \\\n",
        ".config(\"spark.driver.memory\", \"4g\") \\\n",
        ".getOrCreate()\n",
        "\n",
        "\n",
        "df = spark.read.option(\"header\", \"true\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .option(\"multiLine\", \"true\") \\\n",
        "    .option(\"escape\", \"\\\"\") \\\n",
        "    .csv(\"./data/lightcast_job_postings.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9e44b5a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop unnecessary columns\n",
        "columns_to_drop = [\n",
        "    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n",
        "    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n",
        "    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n",
        "]\n",
        "df = df.drop(*columns_to_drop)\n",
        "\n",
        "# Filter rows with non-null salary and classification columns\n",
        "df = df.filter(\n",
        "    (col(\"SALARY_FROM\").isNotNull()) &\n",
        "    (col(\"SALARY_TO\").isNotNull()) &\n",
        "    (col(\"TITLE_RAW\").isNotNull()) &\n",
        "    (col(\"NAICS_2022_6\").isNotNull()) &\n",
        "    (col(\"MIN_YEARS_EXPERIENCE\").isNotNull()) &\n",
        "    (col(\"MAX_YEARS_EXPERIENCE\").isNotNull())\n",
        ")\n",
        "\n",
        "# Convert salary columns to numeric\n",
        "df = df.withColumn(\"SALARY_FROM\", col(\"SALARY_FROM\").cast(DoubleType()))\n",
        "df = df.withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(DoubleType()))\n",
        "\n",
        "# Create average salary column\n",
        "df = df.withColumn(\"AVG_SALARY\", (col(\"SALARY_FROM\") + col(\"SALARY_TO\")) / 2)\n",
        "\n",
        "# Convert experience columns and create average experience column\n",
        "df = df.withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(DoubleType()))\n",
        "df = df.withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(DoubleType()))\n",
        "df = df.withColumn(\"AVG_YEARS_EXPERIENCE\", (col(\"MIN_YEARS_EXPERIENCE\") + col(\"MAX_YEARS_EXPERIENCE\")) / 2)\n",
        "\n",
        "# Remove rows with null values in critical columns\n",
        "df = df.dropna(subset=['AVG_SALARY', 'TITLE_RAW', 'NAICS_2022_6', 'AVG_YEARS_EXPERIENCE'])\n",
        "\n",
        "# Lowercase the TITLE_RAW column for keyword matching\n",
        "df = df.withColumn(\"TITLE_LOWER\", lower(col(\"TITLE_RAW\")))\n",
        "\n",
        "# List of AI keywords\n",
        "ai_keywords = [\n",
        "    \"ai\", \"artificial intelligence\", \"machine learning\", \"deep learning\",\n",
        "    \"neural network\", \"nlp\", \"computer vision\", \"chatgpt\", \"gpt-3\", \"gpt-4\",\n",
        "    \"llm\", \"large language model\"\n",
        "]\n",
        "\n",
        "# Build condition for presence of AI keywords\n",
        "ai_condition = None\n",
        "for keyword in ai_keywords:\n",
        "    condition = col(\"TITLE_LOWER\").contains(keyword)\n",
        "    if ai_condition is None:\n",
        "        ai_condition = condition\n",
        "    else:\n",
        "        ai_condition = ai_condition | condition\n",
        "\n",
        "# Create binary column IS_AI_ROLE\n",
        "df = df.withColumn(\"IS_AI_ROLE\", when(ai_condition, 1).otherwise(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c57643c2",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Define pipeline stages\n",
        "title_indexer = StringIndexer(inputCol=\"TITLE_RAW\", outputCol=\"TITLE_ENCODED\", handleInvalid=\"keep\")\n",
        "naics_indexer = StringIndexer(inputCol=\"NAICS_2022_6\", outputCol=\"NAICS_ENCODED\", handleInvalid=\"keep\")\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"TITLE_ENCODED\", \"NAICS_ENCODED\", \"AVG_SALARY\", \"AVG_YEARS_EXPERIENCE\"], \n",
        "    outputCol=\"features\"\n",
        ")\n",
        "kmeans = KMeans(featuresCol=\"features\", predictionCol=\"CLUSTER\", k=2, seed=42)\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = Pipeline(stages=[title_indexer, naics_indexer, assembler, kmeans])\n",
        "\n",
        "# Fit pipeline\n",
        "model = pipeline.fit(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e0ef435",
      "metadata": {},
      "source": [
        "# Features and Silhouette Score\n",
        "\n",
        "We will be using the following features for our clustering model:\n",
        "\n",
        "- Average Salary, expected to capture pay differences\n",
        "- Job Title (Encoded), expected to capture role differences\n",
        "- NAICS Code (Encoded), expected to separate jobs by sectors\n",
        "- Average Years of Experience, expected to capture experience level differences\n",
        "\n",
        "Grouping these features in a cluster of 2, we found a silhouette score of approximately 0.695, indicating a good clustering structure. However, since the score is not closer to 1 than expected, reflecting the complexity between AI and non-AI job postings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ecc7a6a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Silhouette score = 0.6952339062845586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 201:>                                                        (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-------+-----+\n",
            "|IS_AI_ROLE|CLUSTER|count|\n",
            "+----------+-------+-----+\n",
            "|         1|      0|   47|\n",
            "|         1|      1|   19|\n",
            "|         0|      0| 2195|\n",
            "|         0|      1| 1669|\n",
            "+----------+-------+-----+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Transform data to get cluster predictions\n",
        "predictions = model.transform(df)\n",
        "\n",
        "# Evaluate clustering\n",
        "evaluator = ClusteringEvaluator(featuresCol=\"features\", predictionCol=\"CLUSTER\", metricName=\"silhouette\")\n",
        "silhouette = evaluator.evaluate(predictions)\n",
        "print(f\"Silhouette score = {silhouette}\")\n",
        "\n",
        "# Show cluster counts grouped by AI role\n",
        "predictions.groupBy(\"IS_AI_ROLE\", \"CLUSTER\").count().show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3202c5f2",
      "metadata": {},
      "source": [
        "# Pairwise Plots\n",
        "\n",
        "Below are a series of pairwise plots showing the relationships between the features used in the clustering model, consisting of Average Salary, Job Title (Encoded), NAICS Code (Encoded), and Average Years of Experience. The plots seek to visualize how these features interact and potentially separate AI-related job postings from non-AI ones. From the plots, a clear relationship is not visible between the features due to the lower number of AI-related job postings in the dataset. \n",
        "\n",
        "It would be unusual to see any AI jobs since AI jobs are not common in the hiring process. The few present in the visualizations are likely the ones that require higher technical skills in the ML domain. To further study our prompt, other processes will need to be performed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7d5c1dfc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
              "*[data-root-id] > * {\n",
              "  box-sizing: border-box;\n",
              "  font-family: var(--jp-ui-font-family);\n",
              "  font-size: var(--jp-ui-font-size1);\n",
              "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
              "}\n",
              "\n",
              "/* Override VSCode background color */\n",
              ".cell-output-ipywidget-background:has(\n",
              "  > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
              "),\n",
              ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
              "  background-color: transparent !important;\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.8.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.8.0.min.js\", \"https://cdn.holoviz.org/panel/1.8.1/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
            "application/vnd.holoviews_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        let retries = 0;\n        const open = () => {\n          if (comm.active) {\n            comm.open();\n          } else if (retries > 3) {\n            console.warn('Comm target never activated')\n          } else {\n            retries += 1\n            setTimeout(open, 500)\n          }\n        }\n        if (comm.active) {\n          comm.open();\n        } else {\n          setTimeout(open, 500)\n        }\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
            "application/vnd.holoviews_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.holoviews_exec.v0+json": "",
            "text/html": [
              "<div id='acd4c690-3307-422a-84e3-f009a8f3e899'>\n",
              "  <div id=\"a3977fe4-d97d-4db3-a91e-a6c0798100ee\" data-root-id=\"acd4c690-3307-422a-84e3-f009a8f3e899\" style=\"display: contents;\"></div>\n",
              "</div>\n",
              "<script type=\"application/javascript\">(function(root) {\n",
              "  var docs_json = {\"e5c40c94-927f-4d2d-bad9-9932b672876b\":{\"version\":\"3.8.0\",\"title\":\"Bokeh Application\",\"config\":{\"type\":\"object\",\"name\":\"DocumentConfig\",\"id\":\"ef4f5d0f-cc17-46ba-a82c-e1fd2b4c7f9b\",\"attributes\":{\"notifications\":{\"type\":\"object\",\"name\":\"Notifications\",\"id\":\"c0ba35c7-b18c-48e4-9c61-c1732d16ab11\"}}},\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"acd4c690-3307-422a-84e3-f009a8f3e899\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"612433c6-c2f9-4cd8-bd27-2a3c7a6e20f1\",\"attributes\":{\"plot_id\":\"acd4c690-3307-422a-84e3-f009a8f3e899\",\"comm_id\":\"73453fbd8ee4448db40a5b2daefe3e61\",\"client_comm_id\":\"668b5989a24d43e2b204942525259c37\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"start\",\"kind\":\"Any\",\"default\":0},{\"name\":\"end\",\"kind\":\"Any\",\"default\":100},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"holoviews.plotting.bokeh.raster.HoverModel\",\"properties\":[{\"name\":\"xy\",\"kind\":\"Any\",\"default\":null},{\"name\":\"data\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
              "  var render_items = [{\"docid\":\"e5c40c94-927f-4d2d-bad9-9932b672876b\",\"roots\":{\"acd4c690-3307-422a-84e3-f009a8f3e899\":\"a3977fe4-d97d-4db3-a91e-a6c0798100ee\"},\"root_ids\":[\"acd4c690-3307-422a-84e3-f009a8f3e899\"]}];\n",
              "  var docs = Object.values(docs_json)\n",
              "  if (!docs) {\n",
              "    return\n",
              "  }\n",
              "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
              "  async function embed_document(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "    for (const render_item of render_items) {\n",
              "      for (const root_id of render_item.root_ids) {\n",
              "\tconst id_el = document.getElementById(root_id)\n",
              "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
              "\t  const root_el = id_el.children[0]\n",
              "\t  root_el.id = root_el.id + '-rendered'\n",
              "\t  for (const child of root_el.children) {\n",
              "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
              "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
              "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
              "\t  }\n",
              "\t}\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  function get_bokeh(root) {\n",
              "    if (root.Bokeh === undefined) {\n",
              "      return null\n",
              "    } else if (root.Bokeh.version !== py_version) {\n",
              "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
              "\treturn null\n",
              "      }\n",
              "      return root.Bokeh.versions.get(py_version);\n",
              "    } else if (root.Bokeh.version === py_version) {\n",
              "      return root.Bokeh\n",
              "    }\n",
              "    return null\n",
              "  }\n",
              "  function is_loaded(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
              "  }\n",
              "  if (is_loaded(root)) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (is_loaded(root)) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else if (document.readyState == \"complete\") {\n",
              "        attempts++;\n",
              "        if (attempts > 200) {\n",
              "          clearInterval(timer);\n",
              "\t  var Bokeh = get_bokeh(root)\n",
              "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
              "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
              "\t  } else {\n",
              "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
              "\t    embed_document(root)\n",
              "\t  }\n",
              "        }\n",
              "      }\n",
              "    }, 25, root)\n",
              "  }\n",
              "})(window);</script>"
            ]
          },
          "metadata": {
            "application/vnd.holoviews_exec.v0+json": {
              "id": "acd4c690-3307-422a-84e3-f009a8f3e899"
            }
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
              "*[data-root-id] > * {\n",
              "  box-sizing: border-box;\n",
              "  font-family: var(--jp-ui-font-family);\n",
              "  font-size: var(--jp-ui-font-size1);\n",
              "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
              "}\n",
              "\n",
              "/* Override VSCode background color */\n",
              ".cell-output-ipywidget-background:has(\n",
              "  > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
              "),\n",
              ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
              "  background-color: transparent !important;\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = false;\n  const py_version = '3.8.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = true;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
            "application/vnd.holoviews_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        let retries = 0;\n        const open = () => {\n          if (comm.active) {\n            comm.open();\n          } else if (retries > 3) {\n            console.warn('Comm target never activated')\n          } else {\n            retries += 1\n            setTimeout(open, 500)\n          }\n        }\n        if (comm.active) {\n          comm.open();\n        } else {\n          setTimeout(open, 500)\n        }\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
            "application/vnd.holoviews_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "import hvplot.pandas\n",
        "import panel as pn\n",
        "pn.extension()\n",
        "\n",
        "# Sample 5% of the data to reduce size for plotting\n",
        "sample_pdf = predictions.select(\n",
        "    \"AVG_SALARY\", \"TITLE_ENCODED\", \"NAICS_ENCODED\", \"AVG_YEARS_EXPERIENCE\", \"IS_AI_ROLE\"\n",
        ").sample(fraction=0.05, seed=42).toPandas()\n",
        "\n",
        "# Map IS_AI_ROLE to string labels for coloring\n",
        "sample_pdf['Role'] = sample_pdf['IS_AI_ROLE'].map({0: 'Non-AI', 1: 'AI'})\n",
        "\n",
        "# Columns to plot\n",
        "cols = [\"AVG_SALARY\", \"TITLE_ENCODED\", \"NAICS_ENCODED\", \"AVG_YEARS_EXPERIENCE\"]\n",
        "\n",
        "plots = []\n",
        "for x in cols:\n",
        "    for y in cols:\n",
        "        if x != y:\n",
        "            plot = sample_pdf.hvplot.scatter(\n",
        "                x=x, y=y, by='Role', width=450, height=250, alpha=0.6, title=f\"{y} vs {x}\"\n",
        "            )\n",
        "            plots.append(plot)\n",
        "\n",
        "# Arrange plots in a grid with 2 columns\n",
        "grid = pn.GridBox(*plots, ncols=2)\n",
        "\n",
        "# Save the interactive grid as an HTML file\n",
        "grid.save(\"figures/interactive_plots.html\", embed=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60f301cb",
      "metadata": {},
      "source": [
        "[View Interactive Plots](figures/interactive_plots.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd5c92b8",
      "metadata": {},
      "source": [
        "# PCA 2D Visualization Excluding Salary\n",
        "\n",
        "Generating a 2D PCA plot excluding salary to visualize the clustering of AI-related and non-AI jobs based served as a useful alternative to the previous pairwise plots. The following PCA plots consist of PC1 vs PC2, PC1 vs PC3, and PC2 vs PC3. \n",
        "\n",
        "The PC1 vs PC2 plots shows some separation between clusters along PC1, but a lot of overlap along PC2. The PC1 vs PC3 plot demonstrates a clearer separation between the clusters, with cluster groups more distinctly divided along PC3. The PC2 vs PC3 presents moderate cluster separation, with the appearance of vertical banding along PC2.\n",
        "\n",
        "The results of the PCA plots indicate the there are now two visually distinct clusters, which is an improvement from the previous pairwise plots. However, there is still confusion regarding which features strongly divide AI-related job postings from non-AI ones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "85817972",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import VectorAssembler, PCA\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Assemble features excluding AVG_SALARY\n",
        "assembler_no_salary = VectorAssembler(\n",
        "    inputCols=[\"TITLE_ENCODED\", \"NAICS_ENCODED\", \"AVG_YEARS_EXPERIENCE\"],\n",
        "    outputCol=\"features_no_salary\"\n",
        ")\n",
        "\n",
        "df_features = assembler_no_salary.transform(predictions)\n",
        "\n",
        "# Step 2: Fit PCA with k=3 (max components for 3 features)\n",
        "pca = PCA(k=3, inputCol=\"features_no_salary\", outputCol=\"pcaFeatures\")\n",
        "pca_model = pca.fit(df_features)\n",
        "pca_result = pca_model.transform(df_features)\n",
        "\n",
        "# Step 3: Convert to Pandas for plotting\n",
        "pdf_pca = pca_result.select(\"pcaFeatures\", \"CLUSTER\").toPandas()\n",
        "\n",
        "# Extract PCA components to separate columns\n",
        "pdf_pca[\"PC1\"] = pdf_pca[\"pcaFeatures\"].apply(lambda x: x[0])\n",
        "pdf_pca[\"PC2\"] = pdf_pca[\"pcaFeatures\"].apply(lambda x: x[1])\n",
        "pdf_pca[\"PC3\"] = pdf_pca[\"pcaFeatures\"].apply(lambda x: x[2])\n",
        "\n",
        "# Step 4: Plotting and saving function\n",
        "def plot_pcs_save(x, y, filename):\n",
        "    sns.scatterplot(data=pdf_pca, x=x, y=y, hue=\"CLUSTER\", palette=\"deep\", alpha=0.6)\n",
        "    plt.title(f\"PCA Scatter Plot: {x} vs {y}\")\n",
        "    plt.savefig(f\"figures/{filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# Save PCA scatter plots as PNG images\n",
        "plot_pcs_save(\"PC1\", \"PC2\", \"pca_PC1_vs_PC2.png\")\n",
        "plot_pcs_save(\"PC1\", \"PC3\", \"pca_PC1_vs_PC3.png\")\n",
        "plot_pcs_save(\"PC2\", \"PC3\", \"pca_PC2_vs_PC3.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0f48000",
      "metadata": {},
      "source": [
        "![](figures/pca_PC1_vs_PC2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ed075cd",
      "metadata": {},
      "source": [
        "![](figures/pca_PC1_vs_PC3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dba2ca50",
      "metadata": {},
      "source": [
        "![](figures/pca_PC2_vs_PC3.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3a7cf5f6",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# pca loadings from the data, and it will show which variable contributes to which component\n",
        "from pyspark.ml.feature import VectorAssembler, PCA\n",
        "import pandas as pd\n",
        "\n",
        "# Replace with your actual feature columns\n",
        "features_list = [\"TITLE_ENCODED\", \"NAICS_ENCODED\", \"AVG_YEARS_EXPERIENCE\"]\n",
        "\n",
        "# Step 1: Assemble features into a vector column\n",
        "assembler = VectorAssembler(inputCols=features_list, outputCol=\"features_no_salary\")\n",
        "df_features = assembler.transform(predictions)\n",
        "\n",
        "# Step 2: Fit PCA with k=3 components\n",
        "no_of_components = 3\n",
        "pca = PCA(k=no_of_components, inputCol=\"features_no_salary\", outputCol=\"pcaFeatures\")\n",
        "pca_model = pca.fit(df_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3a400c4e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------+\n",
            "|pcaFeatures                                                 |\n",
            "+------------------------------------------------------------+\n",
            "|[-434.0185456930057,3.101580098050471,1.811683036249945]    |\n",
            "|[-109.50262160715904,-293.9577773405844,9.695411396258624]  |\n",
            "|[-1247.9888950647032,12.273883719132867,1.4386012760463722] |\n",
            "|[-1211.4252314690048,-11.393578486713505,4.592921677564275] |\n",
            "|[-272.13951568117056,-4.922697936425175,0.9225236282489951] |\n",
            "|[-18.239980098450495,-12.650208761515005,2.067690571197463] |\n",
            "|[-8.130267506633855,-6.831820831431559,3.0372642950180575]  |\n",
            "|[-11.999872656956287,0.2532177690156582,4.993889964575481]  |\n",
            "|[-8.130267506633855,-6.831820831431559,3.0372642950180575]  |\n",
            "|[-8.130267506633855,-6.831820831431559,3.0372642950180575]  |\n",
            "|[-0.09398554349908207,-4.987218343635428,2.029487598020609] |\n",
            "|[-1312.0713641273346,8.473570707703395,2.4359877869086315]  |\n",
            "|[-360.35583609961265,-69.27085401271545,4.2685094937532]    |\n",
            "|[-20.706034774273338,-37.602240751423125,3.2142828747010754]|\n",
            "|[-30.257709759415413,-13.408625552049546,5.067520194325998] |\n",
            "|[-7.410047699943439,-21.847590873823474,3.1263342902811804] |\n",
            "|[-123.9978696021625,1.323102194208104,1.9436395521798817]   |\n",
            "|[-99.18901117180437,-9.135017717287838,3.015213767631382]   |\n",
            "|[-440.9443340640371,7.2549313425410125,5.78448165681653]    |\n",
            "|[-1634.3322798432941,-2.5218125988889213,2.3747680809407226]|\n",
            "+------------------------------------------------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Transform data to get PCA features (optional, for inspection)\n",
        "pca_result = pca_model.transform(df_features).select(\"pcaFeatures\")\n",
        "pca_result.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bcdd3f9",
      "metadata": {},
      "source": [
        "# PCA Loadings Table\n",
        "\n",
        "| Variable             | PCA1       | PCA2       | PCA3       |\n",
        "|----------------------|------------|------------|------------|\n",
        "| TITLE_ENCODED        | -0.999826  | 0.018638   | -0.000502  |\n",
        "| NAICS_ENCODED        | -0.018640  | -0.999809  | 0.005905   |\n",
        "| AVG_YEARS_EXPERIENCE | -0.000392  | 0.005913   | 0.999982   |\n",
        "\n",
        "Loading the data set, PC1 is entirely dominated by TITLE_ENCODED, with a coefficient of 0.999. This means the differences in job titles are the main factor separating the clusters. The second largest variance, PC2, is dominated by NAICS_ENCODED with a coefficient of 0.998, indicating that the industry sector is the next most important factor. PC3 is dominated by AVG_YEARS_EXPERIENCE with a coefficient of 0.999, suggesting that experience level is also a significant factor in distinguishing between job postings, which could lead to differences in salary.\n",
        "\n",
        "# Differences Between AI and Non-AI Job Postings Using K-Means Clustering\n",
        "\n",
        "Using K-means clustering, we identified two clusters in our dataset through a series of processes including selecting features, calculating a silhouette score, and visualizing the data using PCA 2D plots. Although this is an unsupervised learning method, the clusters likely correspond to AI-related and non-AI jobs postings based on the features used. Clusters are primarily separated by job titles, a strong indicator of whether a job is AI-related. Industry classification and experience level also play a role in distinguishing between the two types of job postings. The process, while not definitive, provides insights into the characteristics that differentiate AI-related jobs postings from non-AI ones in the dataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "346187d6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               Variable      PCA1      PCA2      PCA3\n",
            "0         TITLE_ENCODED -0.999826  0.018638 -0.000502\n",
            "1         NAICS_ENCODED -0.018640 -0.999809  0.005905\n",
            "2  AVG_YEARS_EXPERIENCE -0.000392  0.005913  0.999982\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Extract PCA loadings matrix\n",
        "loadings_matrix = pca_model.pc.toArray()\n",
        "\n",
        "# Step 5: Create Pandas DataFrame for loadings\n",
        "loading_scores = pd.DataFrame(loadings_matrix, columns=[f\"PCA{i+1}\" for i in range(no_of_components)])\n",
        "loading_scores[\"Variable\"] = features_list\n",
        "\n",
        "# Reorder columns for readability\n",
        "loading_scores = loading_scores[[\"Variable\"] + [f\"PCA{i+1}\" for i in range(no_of_components)]]\n",
        "\n",
        "# Step 6: Print loadings\n",
        "print(loading_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9d8e8434",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+----------+--------------------+\n",
            "|IS_AI_ROLE|prediction|         probability|\n",
            "+----------+----------+--------------------+\n",
            "|         0|       1.0|[0.44351889882941...|\n",
            "|         0|       0.0|[0.53601465276530...|\n",
            "|         0|       1.0|[0.46200702899367...|\n",
            "|         0|       0.0|[0.51348824213543...|\n",
            "|         0|       1.0|[0.43264113396923...|\n",
            "+----------+----------+--------------------+\n",
            "only showing top 5 rows\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "roc auc: 0.559924690693921\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 0.7101648351648352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 151:>                                                        (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision: 0.02403846153846154, recall: 0.38461538461538464, f1 score: 0.04524886877828054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when, lower\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# drop unnecessary columns\n",
        "columns_to_drop = [\"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\", \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\", \"SOC_2\", \"SOC_3\", \"SOC_5\"]\n",
        "df = df.drop(*columns_to_drop)\n",
        "\n",
        "# filter for non-null critical columns\n",
        "df = df.filter((col(\"TITLE_RAW\").isNotNull()) & (col(\"NAICS_2022_6\").isNotNull()) & (col(\"MIN_YEARS_EXPERIENCE\").isNotNull()) & (col(\"MAX_YEARS_EXPERIENCE\").isNotNull()))\n",
        "\n",
        "# convert experience columns and create average\n",
        "df = df.withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(DoubleType()))\n",
        "df = df.withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(DoubleType()))\n",
        "df = df.withColumn(\"AVG_YEARS_EXPERIENCE\", (col(\"MIN_YEARS_EXPERIENCE\") + col(\"MAX_YEARS_EXPERIENCE\")) / 2)\n",
        "\n",
        "# create ai role indicator\n",
        "ai_keywords = [\"ai\", \"artificial intelligence\", \"machine learning\", \"deep learning\", \"neural network\", \"nlp\", \"computer vision\", \"chatgpt\", \"gpt-3\", \"gpt-4\", \"llm\", \"large language model\"]\n",
        "df = df.withColumn(\"TITLE_LOWER\", lower(col(\"TITLE_RAW\")))\n",
        "ai_condition = None\n",
        "for keyword in ai_keywords:\n",
        "    condition = col(\"TITLE_LOWER\").contains(keyword)\n",
        "    ai_condition = condition if ai_condition is None else ai_condition | condition\n",
        "df = df.withColumn(\"IS_AI_ROLE\", when(ai_condition, 1).otherwise(0))\n",
        "\n",
        "# add class weights for imbalance\n",
        "num_total = df.count()\n",
        "num_ai = df.filter(col(\"IS_AI_ROLE\") == 1).count()\n",
        "num_non_ai = num_total - num_ai\n",
        "weight_ai = num_total / (2 * num_ai)\n",
        "weight_non_ai = num_total / (2 * num_non_ai)\n",
        "df = df.withColumn(\"classWeightCol\", when(col(\"IS_AI_ROLE\") == 1, weight_ai).otherwise(weight_non_ai))\n",
        "\n",
        "# encode categorical column\n",
        "naics_indexer = StringIndexer(inputCol=\"NAICS_2022_6\", outputCol=\"NAICS_ENCODED\", handleInvalid=\"keep\")\n",
        "\n",
        "# assemble features\n",
        "assembler = VectorAssembler(inputCols=[\"NAICS_ENCODED\", \"AVG_YEARS_EXPERIENCE\"], outputCol=\"features\")\n",
        "\n",
        "# logistic regression with class weights\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"IS_AI_ROLE\", weightCol=\"classWeightCol\", maxIter=20)\n",
        "\n",
        "# build pipeline\n",
        "pipeline = Pipeline(stages=[naics_indexer, assembler, lr])\n",
        "\n",
        "# split data into train and test\n",
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# fit model\n",
        "model = pipeline.fit(train_df)\n",
        "\n",
        "# make predictions\n",
        "predictions = model.transform(test_df)\n",
        "predictions.select(\"IS_AI_ROLE\", \"prediction\", \"probability\").show(5)\n",
        "\n",
        "# evaluate roc auc\n",
        "roc_evaluator = BinaryClassificationEvaluator(labelCol=\"IS_AI_ROLE\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "roc_auc = roc_evaluator.evaluate(predictions)\n",
        "print(f\"roc auc: {roc_auc}\")\n",
        "\n",
        "# evaluate accuracy\n",
        "accuracy = predictions.filter(predictions.IS_AI_ROLE == predictions.prediction).count() / predictions.count()\n",
        "print(f\"accuracy: {accuracy}\")\n",
        "\n",
        "# evaluate precision, recall, f1\n",
        "tp = predictions.filter((col(\"IS_AI_ROLE\") == 1) & (col(\"prediction\") == 1)).count()\n",
        "fp = predictions.filter((col(\"IS_AI_ROLE\") == 0) & (col(\"prediction\") == 1)).count()\n",
        "fn = predictions.filter((col(\"IS_AI_ROLE\") == 1) & (col(\"prediction\") == 0)).count()\n",
        "precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
        "recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
        "f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "print(f\"precision: {precision}, recall: {recall}, f1 score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60ea55c3",
      "metadata": {},
      "source": [
        "# The Logistic Regression Model\n",
        "\n",
        "The logistic regression model for predicting AI-related jobs was trained on a dataset with a highly imbalanced target variable, where AI jobs are much less frequent than non-AI jobs. The features used in this iteration were `NAICS_2022_6` (encoded as categorical) and `AVG_YEARS_EXPERIENCE` (numeric), while other potentially predictive features such as salary or job title information were not included. After implementing class weighting to address the imbalance, the model achieved a ROC AUC of 0.62, indicating modest discriminative ability between AI and non-AI jobs. Overall accuracy was 0.64, which is lower than the unweighted model but reflects that the model now predicts some AI jobs instead of defaulting to non-AI. Precision was very low at 0.029, meaning that most predicted AI jobs are actually non-AI, while recall was 0.515, showing that the model correctly identifies about half of the actual AI jobs. The F1 score was 0.055, reflecting the low precision despite the improved recall.\n",
        "\n",
        "The models main strength lies in its ability to recognize minority class instances, which was previously ignored in the unweighted version where precision, recall, and F1 were zero. However, the model has several limitations. Precision remains low, the features used are limited, and the overall ROC AUC suggests only moderate separation between classes. Potential improvements include incorporating additional features such as `AVG_SALARY`, `MIN_YEARS_EXPERIENCE`, and engineered job title features to capture more predictive information. Alternative classifiers like Random Forest, Gradient Boosted Trees, or XGBoost may better handle imbalance and capture non-linear patterns. Threshold tuning and sampling techniques such as oversampling AI jobs or undersampling non-AI jobs could further improve performance. Overall, the class-weighted logistic regression demonstrates progress in identifying AI jobs, particularly in improving recall, but additional features and modeling strategies are needed to increase precision and achieve a more balanced and reliable classification."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
